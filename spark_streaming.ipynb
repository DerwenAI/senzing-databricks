{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54742490",
   "metadata": {},
   "source": [
    "# Spark Streaming and Senzing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85510a2a",
   "metadata": {},
   "source": [
    "This notebook shows you how to process streaming data through Apache Spark and send it to Senzing for entity resolution, simulating a real-time data processing pipeline. If you haven't already gone through the `senzing_quickstart.ipynb` tutorial in this repository, we recommend starting with that one because it contains more detailed explanations for each of the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70eff95",
   "metadata": {},
   "source": [
    "### Steps in this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459273ad",
   "metadata": {},
   "source": [
    "1. Set up the Senzing gRPC server, download the `customer.json` data file and split it into 20 separate JSONL files to simulate streaming data.\n",
    "2. Configure the Senzing engine so it's ready to receive data.\n",
    "3. Create a Spark session with streaming capabilities, define a schema and set up a streaming dataframe.\n",
    "4. Implement a batch processing function that takes each streaming batch from Spark, sends individual records to Senzing for entity resolution, and tracks which entities are affected by each record addition.\n",
    "5. Run a cleanup process to ensure the entities are as accurate as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f32414",
   "metadata": {},
   "source": [
    "## Set up requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a0d89",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use the [`senzing`](https://garage.senzing.com/sz-sdk-python/index.html) and [`senzing_grpc`](https://garage.senzing.com/sz-sdk-python-grpc/) packages, in addition to PySpark. Install these using the `requirements.txt` file in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ac5b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.436570Z",
     "iopub.status.busy": "2025-09-16T17:12:18.436393Z",
     "iopub.status.idle": "2025-09-16T17:12:18.533772Z",
     "shell.execute_reply": "2025-09-16T17:12:18.533506Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.436553Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from icecream import ic\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.streaming import StreamingQuery\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from senzing import szengineflags, szerror\n",
    "from senzing_grpc import SzAbstractFactoryGrpc, \\\n",
    "    SzConfigManagerGrpc, SzDiagnosticGrpc, SzEngineGrpc, SzConfigGrpc, SzProductGrpc\n",
    "import grpc\n",
    "import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc6a421d-95df-4948-8843-551dd2e99767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.534193Z",
     "iopub.status.busy": "2025-09-16T17:12:18.534102Z",
     "iopub.status.idle": "2025-09-16T17:12:18.542791Z",
     "shell.execute_reply": "2025-09-16T17:12:18.542532Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.534186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-09-16T10:12:18.534810-07:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.13.3\n",
      "IPython version      : 9.4.0\n",
      "\n",
      "Compiler    : Clang 16.0.0 (clang-1600.0.26.6)\n",
      "OS          : Darwin\n",
      "Release     : 24.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 14\n",
      "Architecture: 64bit\n",
      "\n",
      "json        : 2.0.9\n",
      "requests    : 2.32.5\n",
      "senzing_grpc: 0.5.11\n",
      "pyspark     : 4.0.0\n",
      "watermark   : 2.5.0\n",
      "grpc        : 1.74.0\n",
      "senzing     : 0.2.20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f36227",
   "metadata": {},
   "source": [
    "We'll start our [Senzing gRPC server](https://github.com/senzing-garage/serve-grpc/tree/main) using Docker.\n",
    "\n",
    "Run the following command in a terminal window:\n",
    "\n",
    "```bash\n",
    "docker run -it --publish 8261:8261 --rm senzing/serve-grpc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40530f4a",
   "metadata": {},
   "source": [
    "Then download the example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b64cb50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.543257Z",
     "iopub.status.busy": "2025-09-16T17:12:18.543176Z",
     "iopub.status.idle": "2025-09-16T17:12:18.544906Z",
     "shell.execute_reply": "2025-09-16T17:12:18.544682Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.543248Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path: str = \"./data/\"\n",
    "\n",
    "data_url_prefix: str = \"https://raw.githubusercontent.com/Senzing/truth-sets/refs/heads/main/truthsets/demo/\"\n",
    "\n",
    "filename: str = \"reference.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753c0f18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.545191Z",
     "iopub.status.busy": "2025-09-16T17:12:18.545123Z",
     "iopub.status.idle": "2025-09-16T17:12:18.547061Z",
     "shell.execute_reply": "2025-09-16T17:12:18.546824Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.545184Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(data_path, exist_ok = True)\n",
    "\n",
    "url: str = data_url_prefix + filename\n",
    "filepath: str = data_path + filename\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    response: requests.Response = requests.get(url, stream = True, timeout = 10)\n",
    "    response.raw.decode_content = True\n",
    "\n",
    "    with open(filepath, \"wb\") as file:\n",
    "        shutil.copyfileobj(response.raw, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952a68e",
   "metadata": {},
   "source": [
    "## Create separate JSONL files to simulate streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ae673",
   "metadata": {},
   "source": [
    "We'll use the `reference.json` file from the Senzing \"Truthsets\" <https://github.com/Senzing/truth-sets/> demo data. This dataset contains customer and organization information, with incomplete contact data.\n",
    "\n",
    "We'll save each record from the `reference.json` file into a separate JSONL file to simulate streaming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa194d19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.547486Z",
     "iopub.status.busy": "2025-09-16T17:12:18.547411Z",
     "iopub.status.idle": "2025-09-16T17:12:18.549467Z",
     "shell.execute_reply": "2025-09-16T17:12:18.549246Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.547478Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_streaming_files (\n",
    "        input_file: str,\n",
    "        output_dir: str,\n",
    "    ) -> None:\n",
    "    \"\"\"simulate streaming data\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    \n",
    "    with open(input_file, \"r\") as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            try:\n",
    "                record: dict = json.loads(line)\n",
    "                filename: str = f\"{output_dir}/record_{record['RECORD_ID']}.json\"\n",
    "                \n",
    "                with open(filename, \"w\") as out_file:\n",
    "                    json.dump(record, out_file)\n",
    "                    \n",
    "                print(f\"Created {filename}\")\n",
    "                \n",
    "            except json.JSONDecodeError as ex:\n",
    "                print(f\"Error parsing line {i}: {ex}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f0db36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.551341Z",
     "iopub.status.busy": "2025-09-16T17:12:18.551241Z",
     "iopub.status.idle": "2025-09-16T17:12:18.554672Z",
     "shell.execute_reply": "2025-09-16T17:12:18.554459Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.551334Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data/streaming/record_2012.json\n",
      "Created data/streaming/record_2013.json\n",
      "Created data/streaming/record_2014.json\n",
      "Created data/streaming/record_2041.json\n",
      "Created data/streaming/record_2051.json\n",
      "Created data/streaming/record_2061.json\n",
      "Created data/streaming/record_2071.json\n",
      "Created data/streaming/record_2074.json\n",
      "Created data/streaming/record_2081.json\n",
      "Created data/streaming/record_2091.json\n",
      "Created data/streaming/record_2101.json\n",
      "Created data/streaming/record_2102.json\n",
      "Created data/streaming/record_2111.json\n",
      "Created data/streaming/record_2112.json\n",
      "Created data/streaming/record_2121.json\n",
      "Created data/streaming/record_2122.json\n",
      "Created data/streaming/record_2131.json\n",
      "Created data/streaming/record_2132.json\n",
      "Created data/streaming/record_2141.json\n",
      "Created data/streaming/record_2151.json\n",
      "Created data/streaming/record_2161.json\n",
      "Created data/streaming/record_2162.json\n"
     ]
    }
   ],
   "source": [
    "create_streaming_files(\n",
    "    \"data/reference.json\",\n",
    "    \"data/streaming\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e185bd",
   "metadata": {},
   "source": [
    "## Configure Senzing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec216b",
   "metadata": {},
   "source": [
    "Next, configure the Senzing engine to accept the `reference` dataset, in the same way as the `spark_quickstart.ipynb` tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f446a55e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.554977Z",
     "iopub.status.busy": "2025-09-16T17:12:18.554914Z",
     "iopub.status.idle": "2025-09-16T17:12:18.559010Z",
     "shell.execute_reply": "2025-09-16T17:12:18.558789Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.554970Z"
    }
   },
   "outputs": [],
   "source": [
    "grpc_channel: grpc.Channel = grpc.insecure_channel(\"localhost:8261\")\n",
    "sz_abstract_factory: SzAbstractFactoryGrpc = SzAbstractFactoryGrpc(grpc_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d822b",
   "metadata": {},
   "source": [
    "Check connectivity by getting the Senzing version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec6a775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.559307Z",
     "iopub.status.busy": "2025-09-16T17:12:18.559250Z",
     "iopub.status.idle": "2025-09-16T17:12:18.563856Z",
     "shell.execute_reply": "2025-09-16T17:12:18.563660Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.559301Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"PRODUCT_NAME\": \"Senzing SDK\",\n",
      "  \"VERSION\": \"4.0.0\",\n",
      "  \"BUILD_VERSION\": \"4.0.0.25184\",\n",
      "  \"BUILD_DATE\": \"2025-07-03\",\n",
      "  \"BUILD_NUMBER\": \"2025_07_03__16_38\",\n",
      "  \"COMPATIBILITY_VERSION\": {\n",
      "    \"CONFIG_VERSION\": \"11\"\n",
      "  },\n",
      "  \"SCHEMA_VERSION\": {\n",
      "    \"ENGINE_SCHEMA_VERSION\": \"4.0\",\n",
      "    \"MINIMUM_REQUIRED_SCHEMA_VERSION\": \"4.0\",\n",
      "    \"MAXIMUM_REQUIRED_SCHEMA_VERSION\": \"4.99\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sz_product: SzProductGrpc = sz_abstract_factory.create_product()\n",
    "version_json: str = json.loads(sz_product.get_version())\n",
    "\n",
    "print(\n",
    "    json.dumps(\n",
    "        version_json,\n",
    "        indent = 2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d8e7a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.564234Z",
     "iopub.status.busy": "2025-09-16T17:12:18.564165Z",
     "iopub.status.idle": "2025-09-16T17:12:18.566072Z",
     "shell.execute_reply": "2025-09-16T17:12:18.565834Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.564228Z"
    }
   },
   "outputs": [],
   "source": [
    "sz_configmanager: SzConfigManagerGrpc = sz_abstract_factory.create_configmanager()\n",
    "sz_diagnostic: SzDiagnosticGrpc = sz_abstract_factory.create_diagnostic()\n",
    "sz_engine: SzEngineGrpc = sz_abstract_factory.create_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7324336c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.566461Z",
     "iopub.status.busy": "2025-09-16T17:12:18.566386Z",
     "iopub.status.idle": "2025-09-16T17:12:18.571934Z",
     "shell.execute_reply": "2025-09-16T17:12:18.571685Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.566453Z"
    }
   },
   "outputs": [],
   "source": [
    "config_id: int = sz_configmanager.get_default_config_id()\n",
    "sz_config:SzConfigGrpc = sz_configmanager.create_config_from_config_id(config_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64881f",
   "metadata": {},
   "source": [
    "This time, we'll only use a single data source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a23e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.572356Z",
     "iopub.status.busy": "2025-09-16T17:12:18.572282Z",
     "iopub.status.idle": "2025-09-16T17:12:18.580422Z",
     "shell.execute_reply": "2025-09-16T17:12:18.580174Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.572349Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sz_config.register_data_source(\"REFERENCE\")\n",
    "\n",
    "except (grpc.RpcError, szerror.SzError) as err:\n",
    "    print(err, \"\\n\")\n",
    "    print(\"You only need to register the data source once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e23073d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.580763Z",
     "iopub.status.busy": "2025-09-16T17:12:18.580707Z",
     "iopub.status.idle": "2025-09-16T17:12:18.594660Z",
     "shell.execute_reply": "2025-09-16T17:12:18.594416Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.580755Z"
    }
   },
   "outputs": [],
   "source": [
    "new_json_config: str = sz_config.export()\n",
    "\n",
    "new_config_id: int = sz_configmanager.register_config(\n",
    "    new_json_config,\n",
    "    \"Spark Streaming\",\n",
    ")\n",
    "\n",
    "sz_configmanager.replace_default_config_id(\n",
    "    config_id,\n",
    "    new_config_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b54b6bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:18.595057Z",
     "iopub.status.busy": "2025-09-16T17:12:18.594981Z",
     "iopub.status.idle": "2025-09-16T17:12:19.260137Z",
     "shell.execute_reply": "2025-09-16T17:12:19.259419Z",
     "shell.execute_reply.started": "2025-09-16T17:12:18.595050Z"
    }
   },
   "outputs": [],
   "source": [
    "sz_abstract_factory.reinitialize(new_config_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca643f26",
   "metadata": {},
   "source": [
    "## Set up the Spark Streaming functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dccf1b",
   "metadata": {},
   "source": [
    "Start a new Spark session, create a schema, and then set up a stream reader from Spark's [Structured Streaming](https://spark.apache.org/docs/latest/streaming/index.html) engine. \n",
    "\n",
    "In the next section, we'll use a stream writer to send the data from the Spark Streaming dataframe to Senzing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bddc7b",
   "metadata": {},
   "source": [
    "First, create a Spark session. Ignore any warnings about `NativeCodeLoader` or `jdk.incubator.vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81a8d554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:19.261196Z",
     "iopub.status.busy": "2025-09-16T17:12:19.260979Z",
     "iopub.status.idle": "2025-09-16T17:12:21.202092Z",
     "shell.execute_reply": "2025-09-16T17:12:21.201759Z",
     "shell.execute_reply.started": "2025-09-16T17:12:19.261176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/16 10:12:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Senzing Streaming\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation\", \"/tmp/checkpoint\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449e861b",
   "metadata": {},
   "source": [
    "Providing a schema for our data makes sure that all the files have the correct information.\n",
    "This also speeds up the Spark stream reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a037025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.202510Z",
     "iopub.status.busy": "2025-09-16T17:12:21.202437Z",
     "iopub.status.idle": "2025-09-16T17:12:21.205491Z",
     "shell.execute_reply": "2025-09-16T17:12:21.205245Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.202502Z"
    }
   },
   "outputs": [],
   "source": [
    "customers_schema = StructType([\n",
    "    StructField(\"DATA_SOURCE\", StringType(), True),\n",
    "    StructField(\"RECORD_ID\", StringType(), True),\n",
    "    StructField(\"RECORD_TYPE\", StringType(), True),\n",
    "    StructField(\"PRIMARY_NAME_ORG\", StringType(), True),\n",
    "    StructField(\"SECONDARY_NAME_ORG\", StringType(), True),\n",
    "    StructField(\"PRIMARY_NAME_FULL\", StringType(), True),\n",
    "    StructField(\"NATIVE_NAME_FULL\", StringType(), True),\n",
    "    StructField(\"PRIMARY_NAME_LAST\", StringType(), True),\n",
    "    StructField(\"PRIMARY_NAME_FIRST\", StringType(), True),\n",
    "    StructField(\"PRIMARY_NAME_MIDDLE\", StringType(), True),\n",
    "    StructField(\"GENDER\", StringType(), True),\n",
    "    StructField(\"DATE_OF_BIRTH\", StringType(), True),\n",
    "    StructField(\"PASSPORT_NUMBER\", StringType(), True),\n",
    "    StructField(\"PASSPORT_COUNTRY\", StringType(), True),\n",
    "    StructField(\"DRIVERS_LICENSE_NUMBER\", StringType(), True),\n",
    "    StructField(\"DRIVERS_LICENSE_STATE\", StringType(), True),\n",
    "    StructField(\"SSN_NUMBER\", StringType(), True),\n",
    "    StructField(\"NATIONAL_ID_NUMBER\", StringType(), True),\n",
    "    StructField(\"NATIONAL_ID_COUNTRY\", StringType(), True),\n",
    "    StructField(\"ADDR_TYPE\", StringType(), True),\n",
    "    StructField(\"ADDR_FULL\", StringType(), True),\n",
    "    StructField(\"ADDR_LINE1\", StringType(), True),\n",
    "    StructField(\"ADDR_CITY\", StringType(), True),\n",
    "    StructField(\"ADDR_STATE\", StringType(), True),\n",
    "    StructField(\"ADDR_POSTAL_CODE\", StringType(), True),\n",
    "    StructField(\"ADDR_COUNTRY\", StringType(), True),\n",
    "    StructField(\"PHONE_TYPE\", StringType(), True),\n",
    "    StructField(\"PHONE_NUMBER\", StringType(), True),\n",
    "    StructField(\"EMAIL_ADDRESS\", StringType(), True),\n",
    "    StructField(\"DATE\", StringType(), True),\n",
    "    StructField(\"STATUS\", StringType(), True),\n",
    "    StructField(\"CATEGORY\", StringType(), True),\n",
    "    StructField(\"AMOUNT\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d24be2",
   "metadata": {},
   "source": [
    "The stream reader uses this schema to write to a streaming dataframe. For this example, it reads one file at a time to simulate streaming, but you can easily change this to your input stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2a1c9f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.205843Z",
     "iopub.status.busy": "2025-09-16T17:12:21.205778Z",
     "iopub.status.idle": "2025-09-16T17:12:21.659281Z",
     "shell.execute_reply": "2025-09-16T17:12:21.658973Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.205836Z"
    }
   },
   "outputs": [],
   "source": [
    "streaming_df: DataFrame = spark \\\n",
    "    .readStream \\\n",
    "    .schema(customers_schema) \\\n",
    "    .option(\"maxFilesPerTrigger\", 1)  \\\n",
    "    .json('data/streaming')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496e7a7",
   "metadata": {},
   "source": [
    "## Add records to Senzing and to the Spark Streaming dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55026b",
   "metadata": {},
   "source": [
    "Use the `get_affected_entities` function from the `spark_quickstart` tutorial to track what entities have been changed or created in the Senzing repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b97202b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.659778Z",
     "iopub.status.busy": "2025-09-16T17:12:21.659691Z",
     "iopub.status.idle": "2025-09-16T17:12:21.661362Z",
     "shell.execute_reply": "2025-09-16T17:12:21.661148Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.659770Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_affected_entities (\n",
    "    rec_info: str,\n",
    "    ) -> list:\n",
    "    \"\"\"helper function to extract the `ENTITY_ID`\"\"\"\n",
    "    info: list = json.loads(rec_info)\n",
    "\n",
    "    return [ entity[\"ENTITY_ID\"] for entity in info[\"AFFECTED_ENTITIES\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b512e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.661840Z",
     "iopub.status.busy": "2025-09-16T17:12:21.661755Z",
     "iopub.status.idle": "2025-09-16T17:12:21.663049Z",
     "shell.execute_reply": "2025-09-16T17:12:21.662874Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.661831Z"
    }
   },
   "outputs": [],
   "source": [
    "affected_entities: set = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab17a0",
   "metadata": {},
   "source": [
    "And we'll use the code from the `spark_quickstart.ipynb` tutorial to create a function that will send a streaming batch to the Senzing engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "531c8d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.663457Z",
     "iopub.status.busy": "2025-09-16T17:12:21.663393Z",
     "iopub.status.idle": "2025-09-16T17:12:21.665507Z",
     "shell.execute_reply": "2025-09-16T17:12:21.665333Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.663449Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_streaming_batch (\n",
    "    batch_df: DataFrame,\n",
    "    batch_id: int,\n",
    "    ) -> None:\n",
    "    \"\"\"send a streaming batch to Senzing\"\"\"\n",
    "    if batch_df.count() == 0:\n",
    "        return\n",
    "\n",
    "    print(f\"Processing batch {batch_id} with {batch_df.count()} records\")\n",
    "    \n",
    "    for row in batch_df.rdd.toLocalIterator():\n",
    "        record: dict = {\n",
    "            k: v\n",
    "            for k, v in row.asDict().items()\n",
    "            if v is not None\n",
    "        }\n",
    "        \n",
    "        rec_info: str = sz_engine.add_record(\n",
    "            record[\"DATA_SOURCE\"],\n",
    "            record[\"RECORD_ID\"], \n",
    "            record,\n",
    "            szengineflags.SzEngineFlags.SZ_WITH_INFO,\n",
    "        )\n",
    "        \n",
    "        affected_entities.update(get_affected_entities(rec_info))\n",
    "        print(f\"Added record {record['RECORD_ID']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285d2506",
   "metadata": {},
   "source": [
    "Then, we'll stream the data from the Spark dataframe to Senzing using a Spark stream writer. Ignore any warnings about `ResolveWriteToStream`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6473d93f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.665777Z",
     "iopub.status.busy": "2025-09-16T17:12:21.665722Z",
     "iopub.status.idle": "2025-09-16T17:12:21.849379Z",
     "shell.execute_reply": "2025-09-16T17:12:21.849096Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.665771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/16 10:12:21 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    }
   ],
   "source": [
    "streaming_query: StreamingQuery = streaming_df \\\n",
    "    .writeStream \\\n",
    "    .foreachBatch(process_streaming_batch) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime='10 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8c50c",
   "metadata": {},
   "source": [
    "While this is running, we can get a count of the number of records that have been added to the Senzing repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29fc3f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.851496Z",
     "iopub.status.busy": "2025-09-16T17:12:21.851404Z",
     "iopub.status.idle": "2025-09-16T17:12:21.855796Z",
     "shell.execute_reply": "2025-09-16T17:12:21.855552Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.851487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "result: dict = json.loads(sz_engine.get_stats())\n",
    "print(result[\"workload\"][\"loadedRecords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b65c3f",
   "metadata": {},
   "source": [
    "We can view the `affected_entities` set to confirm that entities have been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1342750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.856218Z",
     "iopub.status.busy": "2025-09-16T17:12:21.856144Z",
     "iopub.status.idle": "2025-09-16T17:12:21.858903Z",
     "shell.execute_reply": "2025-09-16T17:12:21.858693Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.856211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affected_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631141a",
   "metadata": {},
   "source": [
    "And, for each of the entities that have been updated, we can pull the details of that entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c55b3e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.859249Z",
     "iopub.status.busy": "2025-09-16T17:12:21.859171Z",
     "iopub.status.idle": "2025-09-16T17:12:21.860874Z",
     "shell.execute_reply": "2025-09-16T17:12:21.860675Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.859242Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for entity_id in affected_entities:\n",
    "    result: dict = json.loads(sz_engine.get_entity_by_entity_id(entity_id))\n",
    "    print(f\"Entity ID: {str(entity_id)}, Name: {result['RESOLVED_ENTITY']['ENTITY_NAME']}, Record Type: {result['RESOLVED_ENTITY']['FEATURES']['RECORD_TYPE'][0]['FEAT_DESC']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95c004",
   "metadata": {},
   "source": [
    "If you want to scale this up, you can use the `ThreadPoolExecutor` from the Python [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) module, as shown in this example: <https://github.com/brianmacy/sz_incremental_withinfo-v3/blob/main/sz_incremental_withinfo.py>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a6667",
   "metadata": {},
   "source": [
    "## Process REDO records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37aa0c8",
   "metadata": {},
   "source": [
    "As in the `spark_quickstart.ipynb` tutorial, we'll run the Senzing [redo process](https://senzing.zendesk.com/hc/en-us/articles/360007475133-Processing-REDO) to clean up the entities in the Senzing repository, updating the `affected_entities` set as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d95d8aec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.861293Z",
     "iopub.status.busy": "2025-09-16T17:12:21.861232Z",
     "iopub.status.idle": "2025-09-16T17:12:21.867333Z",
     "shell.execute_reply": "2025-09-16T17:12:21.867074Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.861287Z"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    redo_record: str = sz_engine.get_redo_record()\n",
    "    \n",
    "    if not redo_record:\n",
    "        break\n",
    "\n",
    "    rec_info: str = sz_engine.process_redo_record(\n",
    "        redo_record,\n",
    "        flags = SzEngineFlags.SZ_WITH_INFO,\n",
    "    )\n",
    "    \n",
    "    affected_entities.update(get_affected_entities(rec_info))\n",
    "    print(rec_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ab3fd",
   "metadata": {},
   "source": [
    "## Look up the resolved entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c125da2",
   "metadata": {},
   "source": [
    "Now that the entities have been resolved, we can search the Senzing repository for anyone we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f0ea954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.867706Z",
     "iopub.status.busy": "2025-09-16T17:12:21.867638Z",
     "iopub.status.idle": "2025-09-16T17:12:21.874176Z",
     "shell.execute_reply": "2025-09-16T17:12:21.873989Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.867699Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"RESOLVED_ENTITIES\": [\n",
      "    {\n",
      "      \"MATCH_INFO\": {\n",
      "        \"MATCH_LEVEL_CODE\": \"POSSIBLY_SAME\",\n",
      "        \"MATCH_KEY\": \"+NAME\",\n",
      "        \"ERRULE_CODE\": \"SNAME\",\n",
      "        \"CANDIDATE_KEYS\": {\n",
      "          \"NAME_KEY\": [\n",
      "            {\n",
      "              \"FEAT_ID\": 486,\n",
      "              \"FEAT_DESC\": \"ANK|JIE\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"FEATURE_SCORES\": {\n",
      "          \"NAME\": [\n",
      "            {\n",
      "              \"INBOUND_FEAT_ID\": -2,\n",
      "              \"INBOUND_FEAT_DESC\": \"Wang Jie\",\n",
      "              \"CANDIDATE_FEAT_ID\": 482,\n",
      "              \"CANDIDATE_FEAT_DESC\": \"\\u738b\\u6770\",\n",
      "              \"CANDIDATE_FEAT_USAGE_TYPE\": \"NATIVE\",\n",
      "              \"SCORE\": 100,\n",
      "              \"ADDITIONAL_SCORES\": {\n",
      "                \"GNR_FN\": 100,\n",
      "                \"GNR_SN\": -1,\n",
      "                \"GNR_GN\": -1,\n",
      "                \"GENERATION_MATCH\": -1,\n",
      "                \"GNR_ON\": -1\n",
      "              },\n",
      "              \"SCORE_BUCKET\": \"SAME\",\n",
      "              \"SCORE_BEHAVIOR\": \"NAME\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      \"ENTITY\": {\n",
      "        \"RESOLVED_ENTITY\": {\n",
      "          \"ENTITY_ID\": 55,\n",
      "          \"ENTITY_NAME\": \"Jie Wang\",\n",
      "          \"FEATURES\": {\n",
      "            \"ADDRESS\": [\n",
      "              {\n",
      "                \"FEAT_DESC\": \"12 Constitution Street\",\n",
      "                \"LIB_FEAT_ID\": 484,\n",
      "                \"USAGE_TYPE\": \"HOME\",\n",
      "                \"FEAT_DESC_VALUES\": [\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"12 Constitution Street\",\n",
      "                    \"LIB_FEAT_ID\": 484\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ],\n",
      "            \"DOB\": [\n",
      "              {\n",
      "                \"FEAT_DESC\": \"9/14/93\",\n",
      "                \"LIB_FEAT_ID\": 483,\n",
      "                \"FEAT_DESC_VALUES\": [\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"9/14/93\",\n",
      "                    \"LIB_FEAT_ID\": 483\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ],\n",
      "            \"GENDER\": [\n",
      "              {\n",
      "                \"FEAT_DESC\": \"Male\",\n",
      "                \"LIB_FEAT_ID\": 492,\n",
      "                \"FEAT_DESC_VALUES\": [\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"Male\",\n",
      "                    \"LIB_FEAT_ID\": 492\n",
      "                  },\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"M\",\n",
      "                    \"LIB_FEAT_ID\": 319\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ],\n",
      "            \"NAME\": [\n",
      "              {\n",
      "                \"FEAT_DESC\": \"\\u738b\\u6770\",\n",
      "                \"LIB_FEAT_ID\": 482,\n",
      "                \"USAGE_TYPE\": \"NATIVE\",\n",
      "                \"FEAT_DESC_VALUES\": [\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"\\u738b\\u6770\",\n",
      "                    \"LIB_FEAT_ID\": 482\n",
      "                  }\n",
      "                ]\n",
      "              },\n",
      "              {\n",
      "                \"FEAT_DESC\": \"Jie Wang\",\n",
      "                \"LIB_FEAT_ID\": 491,\n",
      "                \"USAGE_TYPE\": \"PRIMARY\",\n",
      "                \"FEAT_DESC_VALUES\": [\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"Jie Wang\",\n",
      "                    \"LIB_FEAT_ID\": 491\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ],\n",
      "            \"NATIONAL_ID\": [\n",
      "              {\n",
      "                \"FEAT_DESC\": \"832721 Hong Kong\",\n",
      "                \"LIB_FEAT_ID\": 493,\n",
      "                \"FEAT_DESC_VALUES\": [\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"832721 Hong Kong\",\n",
      "                    \"LIB_FEAT_ID\": 493\n",
      "                  },\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"832721\",\n",
      "                    \"LIB_FEAT_ID\": 485\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ],\n",
      "            \"RECORD_TYPE\": [\n",
      "              {\n",
      "                \"FEAT_DESC\": \"PERSON\",\n",
      "                \"LIB_FEAT_ID\": 10,\n",
      "                \"FEAT_DESC_VALUES\": [\n",
      "                  {\n",
      "                    \"FEAT_DESC\": \"PERSON\",\n",
      "                    \"LIB_FEAT_ID\": 10\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          \"RECORD_SUMMARY\": [\n",
      "            {\n",
      "              \"DATA_SOURCE\": \"CUSTOMERS\",\n",
      "              \"RECORD_COUNT\": 2\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"SEARCH_STATISTICS\": [\n",
      "    {\n",
      "      \"CANDIDATE_KEYS\": {\n",
      "        \"FEATURE_TYPES\": [\n",
      "          {\n",
      "            \"FTYPE_CODE\": \"NAME_KEY\",\n",
      "            \"FOUND\": 1,\n",
      "            \"NOT_FOUND\": 0,\n",
      "            \"GENERIC\": 0\n",
      "          }\n",
      "        ],\n",
      "        \"SUMMARY\": {\n",
      "          \"FOUND\": 1,\n",
      "          \"NOT_FOUND\": 0,\n",
      "          \"GENERIC\": 0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/16 10:12:21 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "search_query: dict = {\n",
    "    \"name_full\": \"Wang Jie\",\n",
    "}\n",
    "\n",
    "search_result: dict = sz_engine.search_by_attributes(json.dumps(search_query))\n",
    "\n",
    "print(\n",
    "    json.dumps(\n",
    "        json.loads(search_result),\n",
    "        indent = 2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc127d1",
   "metadata": {},
   "source": [
    "You can take a look at the `spark_quickstart` tutorial for details on how to extract data from the Senzing repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6fd08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T17:12:21.874695Z",
     "iopub.status.busy": "2025-09-16T17:12:21.874598Z",
     "iopub.status.idle": "2025-09-16T17:12:21.991111Z",
     "shell.execute_reply": "2025-09-16T17:12:21.990820Z",
     "shell.execute_reply.started": "2025-09-16T17:12:21.874687Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "except Exception as ex:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b9217-23c3-4ad0-bef0-6a96ae63b2de",
   "metadata": {},
   "source": [
    "Ignore any `MicroBatchExecution` errors, though if you want to avoid these see\n",
    "<https://www.waitingforcode.com/apache-spark-structured-streaming/stopping-structured-streaming-query/read>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4eaed",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20793c",
   "metadata": {},
   "source": [
    "If you’re interested in exploring Senzing further, check out the following links:\n",
    "\n",
    "- [Senzing + Docker quickstart](https://senzing.com/docs/quickstart/quickstart_docker/)\n",
    "\n",
    "- [Senzing Learning Portal](https://senzing.com/senzing-learning-portal-signup)\n",
    "\n",
    "- [Senzing SDK Documentation](https://senzing.com/docs/)\n",
    "\n",
    "- [Entity Centric Learning](https://senzing.com/entity-centric-learning-explained/)\n",
    "\n",
    "- [CORD: Collections Of Relatable Data](https://senzing.com/senzing-ready-data-collections-cord)\n",
    "\n",
    "- [Senzing GitHub public repos](https://github.com/senzing-garage)\n",
    "\n",
    "- [\"Graph Power Hour!\" podcast](https://senzing.com/graph-power-hour)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
