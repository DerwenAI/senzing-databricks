{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54742490",
   "metadata": {},
   "source": [
    "# Senzing Entity Resolution Quickstart with Spark/Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f104b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reference dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d00ac0",
   "metadata": {},
   "source": [
    "This tutorial is an introduction to using [Senzing](https://senzing.com/) with Spark dataframes. We'll load three example datasets from Spark dataframes into an instance of Senzing, and we'll find all the entities that are present within this data. This will show us duplicates within the data, and we'll gain the capability to merge the dataframes based on the results from Senzing.\n",
    "\n",
    "We'll use the Senzing \"Truthsets\" demo data from https://github.com/Senzing/truth-sets/. The datasets are as follows:\n",
    "- `customers`, a messy dataset of customer names and incomplete PII data. It includes addresses, dates of birth, emails, etc.\n",
    "- `watchlist`, a list of fraudulent entities\n",
    "- `reference`, containing customer and organization information, with incomplete contact data\n",
    "\n",
    "We'll use the `customers` and `watchlist` datasets to figure out which rows in the `customers` dataset refer to the same entity (person).\n",
    "\n",
    "We'll use the [Senzing V4](https://www.senzing.com/docs/4_beta/python/index.html) syntax and a sandbox Senzing gRPC server hosted within a Docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70eff95",
   "metadata": {},
   "source": [
    "### Steps in this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459273ad",
   "metadata": {},
   "source": [
    "1. Set up the Senzing gRPC server, import the required modules, download the demo data\n",
    "2. Load the data into Spark dataframes\n",
    "3. Configure the Senzing engine so it's ready to receive data\n",
    "4. Add our data to the Senzing repository and resolve entities\n",
    "5. Run a cleanup process to ensure the entities are as accurate as possible.\n",
    "6. Extract the resolved entities from Senzing\n",
    "7. Add a new column to our Spark dataframe containing resolved entity details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f32414",
   "metadata": {},
   "source": [
    "## Set up requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48511fa3",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use the [`senzing`](https://garage.senzing.com/sz-sdk-python/index.html) and [`senzing_grpc`](https://garage.senzing.com/sz-sdk-python-grpc/) packages, in addition to PySpark. You can install both of these using the `requirements.txt` file in the repo folder containing this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac5b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "from senzing import szengineflags, szerror\n",
    "from senzing_grpc import SzAbstractFactoryGrpc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, collect_list, array, array_except\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df69470",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5774d7",
   "metadata": {},
   "source": [
    "We'll start our [Senzing gRPC server](https://github.com/senzing-garage/serve-grpc/tree/main) using Docker.\n",
    "\n",
    "Run the following command `docker run -it --publish 8261:8261 --rm senzing/serve-grpc` in a terminal window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4edaf",
   "metadata": {},
   "source": [
    "Then, we'll download the example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec59153",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"\n",
    "data_url_prefix = \"https://raw.githubusercontent.com/Senzing/truth-sets/refs/heads/main/truthsets/demo/\"\n",
    "data_filenames = [\n",
    "    \"customers.json\",\n",
    "    \"watchlist.json\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf680c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "for filename in data_filenames:\n",
    "    url = data_url_prefix + filename\n",
    "    filepath = data_path + filename\n",
    "    if not os.path.exists(filepath):\n",
    "        response = requests.get(url, stream=True, timeout=10)\n",
    "        response.raw.decode_content = True\n",
    "        with open(filepath, \"wb\") as file:\n",
    "            shutil.copyfileobj(response.raw, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca643f26",
   "metadata": {},
   "source": [
    "## Load data into Spark DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e97a4",
   "metadata": {},
   "source": [
    "First, we'll start a new Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Senzing Quickstart\").master(\"local[*]\").config(\"spark.driver.bindAddress\", \"127.0.0.1\").getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cba04",
   "metadata": {},
   "source": [
    "Next, we'll load the datasets from JSON files into Spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cac0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = spark.read.json(\"data/customers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d797f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d6181",
   "metadata": {},
   "source": [
    "We can see that Robert Smith is in the dataset as Robert, Bob, B, and Robbie, with variations in mailing address and date of birth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54c72c",
   "metadata": {},
   "source": [
    "Next, we'll load the `watchlist` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = spark.read.json(\"data/watchlist.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b62c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b99d78",
   "metadata": {},
   "source": [
    "Both datasets have already been mapped to the [Senzing Entity Specification](https://www.senzing.com/docs/entity_specification/index.html). If you want to use your own data with Senzing, you'll need to map your data to this format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e185bd",
   "metadata": {},
   "source": [
    "## Configure Senzing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b910b",
   "metadata": {},
   "source": [
    "Next, we need to set everything up so that we can call the Senzing engine on the gRPC server. These steps assume that you're running Senzing locally for development purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a86288",
   "metadata": {},
   "source": [
    "Senzing uses an [Abstract Factory](https://garage.senzing.com/sz-sdk-python/senzing.html#module-senzing.szabstractfactory) to create everything that's required to perform entity resolution. We'll create a new abstract factory like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_channel = grpc.insecure_channel(\"localhost:8261\")\n",
    "sz_abstract_factory = SzAbstractFactoryGrpc(grpc_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f671e00",
   "metadata": {},
   "source": [
    "We'll get the Senzing version details to check connectivity and confirm everything is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_product = sz_abstract_factory.create_product()\n",
    "print(json.dumps(json.loads(sz_product.get_version()), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72edafe4",
   "metadata": {},
   "source": [
    "Next, we create the Senzing objects that we need: the configuration manager, the diagnostic in case of errors, and the engine that will perform entity resolution when we load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_configmanager = sz_abstract_factory.create_configmanager()\n",
    "sz_diagnostic = sz_abstract_factory.create_diagnostic()\n",
    "sz_engine = sz_abstract_factory.create_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a710d",
   "metadata": {},
   "source": [
    "We create a new config and add the names of the data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_id = sz_configmanager.get_default_config_id()\n",
    "sz_config = sz_configmanager.create_config_from_config_id(config_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a23e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try/except block to check if data sources already added\n",
    "\n",
    "for data_source in [\"CUSTOMERS\", \"WATCHLIST\"]:\n",
    "    sz_config.register_data_source(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f5aba2",
   "metadata": {},
   "source": [
    "And we replace the default config with our updated config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json_config = sz_config.export()\n",
    "new_config_id = sz_configmanager.register_config(new_json_config, \"Add example data\")\n",
    "sz_configmanager.replace_default_config_id(config_id, new_config_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06cb10b",
   "metadata": {},
   "source": [
    "Because we've changed the Senzing configuration, Senzing objects need to be updated. We do this by reinitializing with the new config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_abstract_factory.reinitialize(new_config_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496e7a7",
   "metadata": {},
   "source": [
    "## Add records to Senzing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d486e",
   "metadata": {},
   "source": [
    "Now that the Senzing engine is set up, we can add our data. We do this using [`sz_engine.add_record()`](https://garage.senzing.com/sz-sdk-python/senzing.html#senzing.szengine.SzEngine.add_record), which adds a single record into the Senzing repository.\n",
    "\n",
    "This method has three required arguments:\n",
    "- `data_source_code`, the identifier that we assigned to each dataset when we added the datasets to the Senzing config. In this tutorial, it's one of ['CUSTOMERS', 'WATCHLIST'].\n",
    "- `record_id`, a unique identifier for each record. This is the `RECORD_ID` column in our example datasets.\n",
    "- `record_definition`, which is the row (record) we're adding.\n",
    "\n",
    "So to simply add a record, we would use the following code:\n",
    "\n",
    "```\n",
    "sz_engine.add_record(record['DATA_SOURCE'],\n",
    "            record['RECORD_ID'],\n",
    "            record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291142a1",
   "metadata": {},
   "source": [
    "We'll add an [optional flag](https://senzing.com/docs/4_beta/flags/flags_add/index.html) so that the Senzing engine outputs the entity ID that is affected when we add each row. Then we'll add this entity ID to a Python set (so that no duplicates are possible). We'll use this later on when we want to extract the details of related entities from Senzing.\n",
    "\n",
    "This is particularly useful when you're adding new data to a large existing dataset, and you only want to see what entities have been affected by the new records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5ccfe",
   "metadata": {},
   "source": [
    "We'll use Spark's local iterator to iterate through each row in each dataframe, convert each row into a dictionary, and add it to the Senzing repository. We'll extract the entity ID from the info printed out by Senzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affected_entities(info_string):\n",
    "    # helper function to extract the entity id\n",
    "    info = json.loads(info_string)\n",
    "    return [entity[\"ENTITY_ID\"] for entity in info[\"AFFECTED_ENTITIES\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6836c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_entities = set()\n",
    "\n",
    "for data_source in [customers, watchlist]:\n",
    "    for row in data_source.rdd.toLocalIterator():\n",
    "        record = {k: v for k, v in row.asDict().items() if v is not None}\n",
    "\n",
    "        info = sz_engine.add_record(\n",
    "            record[\"DATA_SOURCE\"],\n",
    "            record[\"RECORD_ID\"],\n",
    "            record,\n",
    "            szengineflags.SzEngineFlags.SZ_WITH_INFO,\n",
    "        )\n",
    "\n",
    "        affected_entities.update(get_affected_entities(info))\n",
    "        print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a3510",
   "metadata": {},
   "source": [
    "When each row is added, we'll see the details printed out. It should look like this for the first row:\n",
    "\n",
    "`{\"DATA_SOURCE\":\"CUSTOMERS\",\"RECORD_ID\":\"1001\",\"AFFECTED_ENTITIES\":[{\"ENTITY_ID\":1}]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(affected_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a6667",
   "metadata": {},
   "source": [
    "## Process REDO records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637bfd6",
   "metadata": {},
   "source": [
    "The [redo process](https://senzing.zendesk.com/hc/en-us/articles/360007475133-Processing-REDO) in Senzing is a periodic cleanup of the entities in the Senzing repository. You'll need to run the redo process every so often when you're using Senzing with your own data.\n",
    "\n",
    "The most common use for this is when Senzing discovers a value is overused across entities. You might add 50 records with different names but the same phone number. At first, the shared phone number suggests that these entities are related, but at a certain point the system will spot that the phone number is no longer a good identifier. It will then create redo records in a separate table, and you can run the redo process to clean up the entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98f1ca",
   "metadata": {},
   "source": [
    "We'll run the redo process using `sz_engine.get_redo_record()`, which gets each record in the redo table, and `sz_engine.process_redo_record()`, which cleans up the entities based on the redo record. Carrying out this process can generate more records in the redo table, so we'll run it in a `while` loop until there are no more redo records.\n",
    "\n",
    "We'll also use the `SZ_WITH_INFO` flag again to output the affected entities, and we'll update our set of affected entities with these entity IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    redo_record = sz_engine.get_redo_record()\n",
    "    if not redo_record:\n",
    "        break\n",
    "    info = sz_engine.process_redo_record(redo_record, flags=szengineflags.SzEngineFlags.SZ_WITH_INFO)\n",
    "    affected_entities.update(get_affected_entities(info))\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd16163c",
   "metadata": {},
   "source": [
    "### Take a look at some results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a77589",
   "metadata": {},
   "source": [
    "Let's take a quick look at the entities found by Senzing. We know that there's someone named Robert Smith in the dataset, and we think their date of birth is 11/12/1978. We can look them up in the Senzing repository using `sz_engine.search_by_attributes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = {\n",
    "    \"name_full\": \"robert smith\",\n",
    "    \"date_of_birth\": \"11/12/1978\",\n",
    "}\n",
    "search_result = sz_engine.search_by_attributes(json.dumps(search_query))\n",
    "print(json.dumps(json.loads(search_result), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33cbfd7",
   "metadata": {},
   "source": [
    "We can see all the information about the Robert Smith entity that is currently in the Senzing repository. This person is also in our datasets with the names \"B Smith\", \"Bob J Smith\" and \"Bob Smith\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ab3fd",
   "metadata": {},
   "source": [
    "## Add resolved entities to the Spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e24cf",
   "metadata": {},
   "source": [
    "Our final step in this tutorial is to add a new column to the `customers` dataframe containing a list of all the resolved entities found by Senzing.\n",
    "\n",
    "So if records 1001, 1002 and 1003 are linked to the same entity, we'll add the list [1002, 1003] to the row for record 1001.\n",
    "\n",
    "You could then use this information to merge rows in the original dataframe, but we won't cover this in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43431a",
   "metadata": {},
   "source": [
    "### Get entity mappings from Senzing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488ed2d",
   "metadata": {},
   "source": [
    "We'll use our list of affected entities to extract all the resolved entities, then we'll build a map from the entity ID to all the record IDs for that entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records_for_entity(entity_id):\n",
    "    records = json.loads(sz_engine.get_entity_by_entity_id(entity_id))[\n",
    "        \"RESOLVED_ENTITY\"\n",
    "    ][\"RECORDS\"]\n",
    "    return [records[i][\"RECORD_ID\"] for i in range(len(records))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f611230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build entity to record map\n",
    "entity_to_record = {}\n",
    "for entity in affected_entities:\n",
    "    try:\n",
    "        entity_to_record[entity] = get_records_for_entity(entity)\n",
    "    except szerror.SzError:\n",
    "        entity_to_record[entity] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ad9ff",
   "metadata": {},
   "source": [
    "The first entries in this dictionary should look like this:\n",
    "\n",
    "```\n",
    "{1: ['1002', '1001', '1003', '1004'],\n",
    " 5: ['1005', '1006'],\n",
    " 6: ['1009', '1010', '1011', '1012', '1014'],\n",
    " ...`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380318ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_to_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc9f5a6",
   "metadata": {},
   "source": [
    "## Join entity records to Spark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1bce0",
   "metadata": {},
   "source": [
    "Our final step in this tutorial is to create a new column with details of all the rows that Senzing has resolved to the same entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314b22e",
   "metadata": {},
   "source": [
    "To build this column, we'll first flatten the entity to record map and convert it to a new Spark dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5107600",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_record_data = [\n",
    "    (entity_id, record_id)\n",
    "    for entity_id, records in entity_to_record.items()\n",
    "    for record_id in records\n",
    "]\n",
    "entity_record_df = spark.createDataFrame(entity_record_data, [\"ENTITY_ID\", \"RECORD_ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a8d99",
   "metadata": {},
   "source": [
    "Then, we'll group this new dataframe by the entity ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e19374",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_grouped = entity_record_df.groupBy(\"ENTITY_ID\").agg(\n",
    "    collect_list(\"RECORD_ID\").alias(\"ALL_RECORD_IDS\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76c3bc",
   "metadata": {},
   "source": [
    "We'll join it to the original `customers` dataframe, and we'll also add a column with the entity ID for that row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4337e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = customers.join(entity_record_df, \"RECORD_ID\", \"left\")\n",
    "customers = customers.join(entity_grouped, \"ENTITY_ID\", \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e865418b",
   "metadata": {},
   "source": [
    "And we'll make a new column without the original RECORD_ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = customers.withColumn(\n",
    "    \"RELATED_RECORD_IDS\",\n",
    "    array_except(col(\"ALL_RECORD_IDS\"), array(col(\"RECORD_ID\").cast(\"string\"))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310451d1",
   "metadata": {},
   "source": [
    "There's now a column in our `customers` dataframe that contains all the other records that have been resolved to the same entity! It should look like this:\n",
    "\n",
    "| RECORD_ID | ENTITY_ID | RELATED_RECORD_IDS |\n",
    "|-----------|-----------|-------------------|\n",
    "| 1004 |1|[1002, 1001, 1003] |\n",
    "|1010|6|[1009, 1011, 1012, 1014]|\n",
    "|1016|9|[1015, 1017, 1018]|\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.select(\"RECORD_ID\", \"ENTITY_ID\", \"RELATED_RECORD_IDS\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c6901",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Link to new tutorial\n",
    "\n",
    "TODO where else should people go if they want to learn more?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senzing-databricks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
